# -*- coding: utf-8 -*-
"""stacking-utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11DPTzmkp74ZFu7Q7fLAbg4Nx1oD7yYem
"""

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

from datetime import datetime, date, timedelta
from hijri_converter import Hijri, Gregorian
from prophet import Prophet
from neuralprophet import NeuralProphet, set_log_level
set_log_level("ERROR")

from catboost import CatBoostRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_percentage_error
from pandas.tseries.offsets import MonthEnd

from keras.layers import Dense,Dropout,Embedding,LSTM
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam, SGD
from keras.models import Sequential

import warnings
warnings.filterwarnings("ignore")

import logging
logging.disable(logging.CRITICAL)

def load_data(uploaded_data):

    uploaded_data_path = uploaded_data.name
    if '.csv' in str(uploaded_data_path):
        data = pd.read_csv(uploaded_data)
    elif '.xls' in str(uploaded_data_path):
        data = pd.read_excel(uploaded_data)
    else: 
        raise(ImportError("Invalid file extension for uploaded file - must be .csv or .xls or .xlsx"))
    return data


#Format Adjustment (required by Prophet Model)
def pre_format(df):
  df = df.rename(columns = {'date' : 'ds', 'total_order' : 'y'})
  df['ds'] = df['ds'].astype('datetime64[ns]') 
  return df

#Warehouse Filtering
def select_wh(df, wh, train_start_date, pred_date):
  df = pre_format(df)
  df = df[df['warehouse_agg'] == wh] 
  df['ds_Ym'] = df['ds'].dt.strftime("%Y-%m")
  df = df[~df.ds.duplicated(keep='first')]
  df = df[(df['ds_Ym']>=train_start_date[wh])&(df['ds_Ym']<pred_date)]
  return df

def create_prediction_range(df, pred_month):
  range = pd.DataFrame({'ds': pd.date_range(start = pd.to_datetime(str(pred_month) + '-01'), end = pd.to_datetime(str(pred_month) + '-01') + MonthEnd(1))})
  return range


#####################################################
#                     PROPHET
######################################################

# twin_dates(), is_tokopedia(), is_shopee(), is_payday(), is_covid(), is_ramadhan(),
# merupakan function yang diperlukan dalam membuat feature untuk modelling Prophet
def twin_dates(date, month):
    date_month, date_day = date.month, date.day
    if (date_month == month) and (date_day == month):
      return 1
    else:
      return 0

tokopedia_wib = [25, 26, 27, 28, 29, 30, 31]
def is_tokopedia(date):
    month, day = date.month, date.day
    if (month == day) or (day in tokopedia_wib):
      return True
    else: 
      return False

shopee_payday = [25, 26, 27]
def is_shopee(date):
    month, day = date.month, date.day
    if (month == day) or (day in shopee_payday):
      return True
    else: 
      return False

def is_payday(date):
    if date.day == 25:
      return True
    else: 
      return False

def is_covid(date): 
    if date > datetime.strptime('2021-03-02', "%Y-%m-%d"):
      return 1
    else: 
      return 0

def is_ramadhan(date):
  year, month, day = date.year, date.month, date.day

  hijriah_date = Gregorian(year, month, day).to_hijri()
  hijriah_month = hijriah_date.month_name()

  if hijriah_month == 'Ramdhan':
    return True
  else:
    return False

# add_twin_dates_feature() dan add_main_feature()
# merupakan function yang digunakan untuk membuat feature pada dataset
def add_twin_dates_feature(df):
  for month in [i + 1 for i in range(12)]:
    feature_name = 'twin_dates_' + str(month)
    df[feature_name] = df['ds'].apply(lambda x:twin_dates(x, month))
  return df

def add_main_feature(df):
  feature_name_str = ['is_covid','is_tokopedia','is_shopee','is_payday','is_ramadhan']
  feature_name = [is_covid,is_tokopedia,is_shopee,is_payday,is_ramadhan]
  for feature, name in enumerate(feature_name_str):
    df[name] = df['ds'].apply(feature_name[feature])
  return df

def val_add_feature(train_data, val_data):
  train_data, val_data = add_main_feature(train_data), add_main_feature(val_data)
  train_data, val_data = add_twin_dates_feature(train_data), add_twin_dates_feature(val_data)
  return train_data, val_data

# prophet_model() sebagai function modelling
def prophet_model(df, future):
  m = Prophet(seasonality_mode = 'multiplicative')

  m.add_country_holidays('ID') 
  for regressor in ['is_covid','is_tokopedia','is_shopee','is_payday','is_ramadhan']:
    m.add_regressor(regressor)

  for month in [i + 1 for i in range(12)]:
    feature_name = 'twin_dates_' + str(month)
    m.add_regressor(feature_name)

  m.fit(df)
  forecast = m.predict(future)
  return forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]

def stack_prophet(df, future):
  df, future = val_add_feature(df, future)
  result = prophet_model(df, future)
  merged_p = result[['ds','yhat']]
  merged_p.columns = ['ds','y_prophet']
  return merged_p

#####################################################
#                   NEURALPROPHET
######################################################

# special_event_list(),
# merupakan function yang diperlukan dalam membuat feature untuk modelling NeuralProphet
def special_event_list(start_year, length):
  event_tokped = []
  for year in range(start_year,start_year + length):
    for month in [i + 1 for i in range(12)]:
      for j in [25,26,27,28,29,30,31]:
        event_date = str(year) + '-' + str(month) + '-' + str(j)
        event_tokped.append(event_date)

  event_shopee = []
  for year in range(start_year,start_year + length):
    for month in [i + 1 for i in range(12)]:
      for j in [25,26,27]:
        event_date = str(year) + '-' + str(month) + '-' + str(j)
        event_shopee.append(event_date)

  event_payday = []
  for year in range(start_year,start_year + length):
    for month in [i + 1 for i in range(12)]:
      event_date = str(year) + '-' + str(month) + '-25'
      event_payday.append(event_date)

  event_ramadhan = []
  for year in range(start_year-579,start_year-579+length):
    for day in range(1,30):
      try:
        ramadhan_day = Hijri.fromisoformat(str(year)+'-09-'+str(day)).to_gregorian().isoformat()
        event_ramadhan.append(ramadhan_day)
      except ValueError:
        pass

  event_twin = []
  for year in range(start_year,start_year + length):
    for month in [i + 1 for i in range(12)]:
      event_date = str(year) + '-' + str(month) + '-' + str(month)
      event_twin.append(event_date)

  return event_tokped, event_shopee, event_payday, event_ramadhan, event_twin

# create_event_df() dan merged_event_df() diperlukan untuk membangun dataframe 'Special Events' bagi NeuralProphet
def create_event_df(event_tokped, event_shopee, event_payday, event_ramadhan, event_twin):
  event_tokped_df = pd.DataFrame({'event': 'tokped', 'ds': pd.to_datetime(event_tokped, errors="coerce"),})
  event_tokped_df = event_tokped_df.dropna(axis=0, subset=['ds'])
  event_shopee_df = pd.DataFrame({'event': 'shopee', 'ds': pd.to_datetime(event_shopee),})
  event_payday_df = pd.DataFrame({'event': 'payday', 'ds': pd.to_datetime(event_payday),})
  event_ramadhan_df = pd.DataFrame({'event': 'ramadhan', 'ds': pd.to_datetime(event_ramadhan),})
  event_twin_df = pd.DataFrame({'event': 'twin', 'ds': pd.to_datetime(event_twin),})
  return event_tokped_df, event_shopee_df, event_payday_df, event_ramadhan_df, event_twin_df

def merged_event_df(start_year,length):
  event_tokped, event_shopee, event_payday, event_ramadhan, event_twin = special_event_list(start_year,length)
  event_tokped_df, event_shopee_df, event_payday_df, event_ramadhan_df, event_twin_df = create_event_df(event_tokped, event_shopee, event_payday, event_ramadhan, event_twin)
  events_df = pd.concat((event_tokped_df, event_shopee_df, event_payday_df, event_ramadhan_df, event_twin_df))
  return events_df

# neuralprophet_model() sebagai function modelling
def neuralprophet_model(df, future, events_df):
  m = NeuralProphet()
  m = m.add_country_holidays("ID")
  m = m.add_events(["tokped","shopee","payday","ramadhan","twin"],  mode="multiplicative")
  events_df = merged_event_df(start_year=2018,length=datetime.now().year - 2018 + 2)
  history_df = m.create_df_with_events(df, events_df)
  history_df = history_df[['ds', 'y', 'tokped','shopee', 'payday', 'ramadhan','twin']]

  metrics = m.fit(history_df, freq="D")

  future_np = m.make_future_dataframe(df=history_df, events_df=events_df, periods=future.shape[0], n_historic_predictions=len(df))
  forecast = m.predict(df=future_np)
  forecast = forecast[forecast['ds'].isin(future['ds'].astype(str).values)]
  return forecast[['ds', 'yhat1']]

def stack_neural_prophet(df, future):
  events_df = merged_event_df(start_year=2018,length=datetime.now().year - 2018 + 2)
  result = neuralprophet_model(df, future, events_df)
  result.columns = ['ds','y_neural_prophet']
  return result

#####################################################
#                     TREEBASED
######################################################

#adding feature to existing dataframe
def fe_eng(df):
  df['month'], df['day'], df['year'] = df['ds'].dt.month, df['ds'].dt.dayofweek, df['ds'].dt.year
  df = df.replace({False: 0, True: 1})
  return df
  
#adding lag feature with 1 month shift
def lagged1M(df, train_start): 
  df['ds-1']= df['ds'] - pd.DateOffset(months=1)
  temp = df[['ds','y']].copy()
  df = df[df['ds_Ym']>train_start]
  temp.columns = ['ds-1','y-1M']
  hi = pd.merge(df, temp, how='left', on=['ds-1'])
  hi = hi.drop(columns=['ds-1']).dropna()
  return hi

def twindates_list(start_year, length):
  event_twin = []
  for year in range(start_year,start_year + length):
    for month in [i + 1 for i in range(12)]:
      event_date = str(year) + '-' + str(month) + '-' + str(month)
      event_twin.append(event_date)
  return pd.to_datetime(event_twin)

def is_twindate(date):
  event_twin_list = twindates_list(2018, datetime.now().year - 2018 + 2)
  if date in event_twin_list:
    return True
  else:
    return False

def tree_based_lstm_split(df, future, WH):
  train_start_date = {'ALL BSD':'2020-11','ALL LEGOK 10K':'2020-10','ALL LEGOK B6, A7':'2021-01','ALL SURABAYA':'2021-09','ALL FF':'2021-11'}

  future['is_tokopedia_promo'] = future['ds'].apply(is_tokopedia)
  future['is_shopee_promo'] = future['ds'].apply(is_shopee)
  future['is_payday'] = future['ds'].apply(is_payday)
  future['is_twindate'] = future['ds'].apply(is_twindate)
  df['is_payday'] = df['ds'].apply(is_payday)

  df = fe_eng(df)
  future = fe_eng(future)

  df = lagged1M(df, train_start_date[WH])

  future['ds_temp']= future['ds'] - pd.DateOffset(months=1)
  df['ds_temp'] = df['ds']

  future = pd.merge(future, df[['ds_temp','y']], on=['ds_temp'], how='left')
  future = future.rename(columns = {'y':'y-1M'})

  X_train, y_train = df[['is_tokopedia_promo', 'is_shopee_promo','is_twindate', 'is_payday', 'month', 'day', 'year','y-1M']], df['y']
  X_test = future[['is_tokopedia_promo', 'is_shopee_promo','is_twindate', 'is_payday', 'month', 'day', 'year','y-1M']]
  return X_train, y_train, X_test
  
def stack_rf(df, future, WH):
  X_train, y_train, X_test = tree_based_lstm_split(df, future, WH)

  if WH == 'ALL BSD':
    rf = RandomForestRegressor(n_estimators=250, max_depth=5, min_samples_split=6, min_samples_leaf=2, max_features=3, random_state=7)
  elif WH == 'ALL LEGOK 10K':
    rf = RandomForestRegressor(n_estimators=750, max_depth=20, min_samples_split=6, min_samples_leaf=1, max_features=4, random_state=7)
  elif WH == 'ALL LEGOK B6, A7':
    rf = RandomForestRegressor(n_estimators=100, max_depth=3, min_samples_split=2, min_samples_leaf=1, max_features=3, random_state=7)
  elif WH == 'ALL SURABAYA':
    rf = RandomForestRegressor(n_estimators=500, max_depth=3, min_samples_split=6, min_samples_leaf=1, max_features=2, random_state=7)
  elif WH == 'ALL FF':
    rf = RandomForestRegressor(n_estimators=100, max_depth=3, min_samples_split=2, min_samples_leaf=1, max_features=2, random_state=7)

  rf.fit(X_train, y_train)
  y_pred = rf.predict(X_test)
  merged_rf = pd.DataFrame(y_pred, columns=['y_pred'])
  merged_rf['ds'] = future['ds'].values
  merged_rf.columns = ['y_rf','ds']
  return merged_rf

def stack_cb(df, future, WH):
  X_train, y_train, X_test = tree_based_lstm_split(df, future, WH)

  if WH == 'ALL BSD':
    cb = CatBoostRegressor(n_estimators=250, max_depth=2, learning_rate=0.1,random_state=7,logging_level='Silent')
  elif WH == 'ALL LEGOK 10K':
    cb = CatBoostRegressor(n_estimators=750, max_depth=2, learning_rate=0.05,random_state=7,logging_level='Silent')
  elif WH == 'ALL LEGOK B6, A7':
    cb = CatBoostRegressor(n_estimators=500, max_depth=2, learning_rate=0.01,random_state=7,logging_level='Silent')
  elif WH == 'ALL SURABAYA':
    cb = CatBoostRegressor(n_estimators=100, max_depth=2, learning_rate=0.03,random_state=7,logging_level='Silent')
  elif WH == 'ALL FF':
    cb = CatBoostRegressor(n_estimators=1000, max_depth=4, learning_rate=0.01,random_state=7,logging_level='Silent')

  cb.fit(X_train, y_train)
  y_pred = cb.predict(X_test)
  merged_cb = pd.DataFrame(y_pred, columns=['y_pred'])
  merged_cb['ds'] = future['ds'].values
  merged_cb.columns = ['y_cb','ds']
  return merged_cb

#####################################################
#                             LSTM
######################################################

# model_lstm() sebagai function modelling
def model_lstm(X_train, y_train, X_val, n_steps, n_features):
  model = Sequential()
  model.add(LSTM(100, activation='relu', input_shape=(n_steps, n_features)))
  model.add(Dense(1))
  model.compile(optimizer=Adam(lr=0.005), loss='mse')

  early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_loss', patience = 2)
  callback = [early_stopping]

  history = model.fit(X_train, y_train,  validation_split=0.1, epochs=30, verbose=0, callbacks=callback)
  y_pred = model.predict(X_val)
  return y_pred

def stack_lstm_3x(df, future, WH):
  X_train, y_train, X_test = tree_based_lstm_split(df, future, WH)

  X_train, y_train  = X_train.to_numpy(), y_train.to_numpy()
  X_test = X_test.to_numpy()

  n_features = 1
  n_steps = X_train.shape[1]
  X_train= X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))
  X_val= X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))

  temp = pd.DataFrame(index=range(X_val.shape[0]))
  temp2 = pd.DataFrame(index=range(X_val.shape[0]))

  for i in range(3):    
    y_pred = model_lstm(X_train, y_train, X_test, n_steps, n_features)
    merged_lstm = pd.DataFrame(y_pred, columns=['y_pred'])
    merged_lstm['ds'] = future['ds'].values
    merged_lstm.columns = ['y_lstm','ds']
    temp['y-'+str(i)] = merged_lstm['y_lstm'].reset_index(drop=True)
  
  temp2['ds'] = merged_lstm['ds']
  temp2['y_lstm_avg'] = temp.mean(axis=1) 
  return temp2

#####################################################
#                         STACK
######################################################
def stack_model(df, future, WH, model_name_list):
  """
  Parameters:
  df - dataframe yang diperoleh dari select_wh_val()
  WH - nama Warehouse yang digunakan, dipakai untuk penentuan hyperparameter optimal tree-based model
  model_name_list - list of model yang digunakan dalam stacking
  val_dates - list of important dates dari csv yang sudah diimport di atas
  train_start - starting month for training
  val_month_start - validation month
  total_pass - total split pada expanding window

  Returns:
  stack - dataframe gabungan hasil forecast
  sum(mape_list)/total_pass - rata-rata MAPE
  mape_list - MAPE masing-masing pass sebelum diambil average
  """
  merged_p = stack_prophet(df, future)
  merged_np = stack_neural_prophet(df, future)
  merged_rf = stack_rf(df, future, WH)
  merged_cb = stack_cb(df, future, WH)  
  merged_lstm_avg = stack_lstm_3x(df, future, WH)

  model_name = {"prophet":merged_p, "neural_prophet":merged_np, "rf":merged_rf,"cb":merged_cb,"lstm":merged_lstm_avg}
    
  merged_stack = [df.set_index(['ds']) for df in map(model_name.get, model_name_list)]
  stack = pd.concat(merged_stack, axis=1).reset_index()
  stack['y_avg'] = stack.drop(columns=['ds']).mean(axis=1)
  stack = stack[stack['ds'].isin(val_dates)]

  return stack

